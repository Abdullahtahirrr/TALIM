[Document(metadata={'source': 'Data\\AI-Lecture Note 6 Slides Version 1.pdf', 'page': 0}, page_content='Dr. Seemab latif\nLecture 7\n12 Nov 2024\nA R T I F I C I A L  I N T E L L I G E N C E'), Document(metadata={'source': 'Data\\AI-Lecture Note 6 Slides Version 1.pdf', 'page': 1}, page_content='[These slides were created by Dan Klein and Pieter Abbeel for CS188 Intro to AI at UC Berkeley.]\nProbability'), Document(metadata={'source': 'Data\\AI-Lecture Note 6 Slides Version 1.pdf', 'page': 2}, page_content='Today\n\uf0a7 Probability\n\uf0a7 Random Variables\n\uf0a7 Joint and Marginal Distributions\n\uf0a7 Conditional Distribution\n\uf0a7 Product Rule, Chain Rule, Bayes’ Rule\n\uf0a7 Inference\n\uf0a7 Independence\n\uf0a7 You’ll need all this stuff A LOT for the \nnext few weeks, so make sure you go \nover it now!\n'), Document(metadata={'source': 'Data\\AI-Lecture Note 6 Slides Version 1.pdf', 'page': 3}, page_content='Inference in Ghostbusters\n\uf0a7 A ghost is in the grid \nsomewhere\n\uf0a7 Sensor readings tell how \nclose a square is to the \nghost\n\uf0a7 On the ghost: red\n\uf0a7 1 or 2 away: orange\n\uf0a7 3 or 4 away: yellow\n\uf0a7 5+ away: green\nP(red | 3) P(orange | 3) P(yellow | 3) P(green | 3)\n0.05 0.15 0.5 0.3\n\uf0a7 Sensors are noisy, but we know P(Color | Distance)\n[Demo: Ghostbuster – no probability (L12D1) ]'), Document(metadata={'source': 'Data\\AI-Lecture Note 6 Slides Version 1.pdf', 'page': 4}, page_content='Video of Demo Ghostbuster – No probability\n'), Document(metadata={'source': 'Data\\AI-Lecture Note 6 Slides Version 1.pdf', 'page': 5}, page_content='Uncertainty\n\uf0a7 General situation:\n\uf0a7 Observed variables (evidence): Agent knows certain \nthings about the state of the world (e.g., sensor \nreadings or symptoms)\n\uf0a7 Unobserved variables: Agent needs to reason about \nother aspects (e.g. where an object is or what disease is \npresent)\n\uf0a7 Model: Agent knows something about how the known \nvariables relate to the unknown variables\n\uf0a7 Probabilistic reasoning gives us a framework for \nmanaging our beliefs and knowledge\n'), Document(metadata={'source': 'Data\\AI-Lecture Note 6 Slides Version 1.pdf', 'page': 6}, page_content='Random Variables\n\uf0a7 A random variable is some aspect of the world about \nwhich we (may) have uncertainty\n\uf0a7 R = Is it raining?\n\uf0a7 T = Is it hot or cold?\n\uf0a7 D = How long will it take to drive to work?\n\uf0a7 L = Where is the ghost?\n\uf0a7 We denote random variables with capital letters\n\uf0a7 Random variables have domains\n\uf0a7 R in {true, false}   (often write as {+r, -r})\n\uf0a7 T in {hot, cold}\n\uf0a7 D in [0, \uf0a5)\n\uf0a7 L in possible locations, maybe {(0,0), (0,1), …}\n'), Document(metadata={'source': 'Data\\AI-Lecture Note 6 Slides Version 1.pdf', 'page': 7}, page_content='Probability Distributions\n\uf0a7 Associate a probability with each value\n\uf0a7 Temperature:\nT P\nhot 0.5\ncold 0.5\nW P\nsun 0.6\nrain 0.1\nfog 0.3\nmeteor 0.0\n\uf0a7 Weather: '), Document(metadata={'source': 'Data\\AI-Lecture Note 6 Slides Version 1.pdf', 'page': 8}, page_content='Shorthand notation:\nOK if all domain entries are unique\nProbability Distributions\n\uf0a7 Unobserved random variables have distributions\n\uf0a7 A distribution is a TABLE of probabilities of values\n\uf0a7 A probability (lower case value) is a single number\n\uf0a7 Must have:                                                 and\nT P\nhot 0.5\ncold 0.5\nW P\nsun 0.6\nrain 0.1\nfog 0.3\nmeteor 0.0\n'), Document(metadata={'source': 'Data\\AI-Lecture Note 6 Slides Version 1.pdf', 'page': 9}, page_content='Joint Distributions\n\uf0a7 A joint distribution over a set of random variables:\nspecifies a real number for each assignment (or outcome): \n\uf0a7 Must obey:\n\uf0a7 Size of distribution if n variables with domain sizes d?\n\uf0a7 For all but the smallest distributions, impractical to write out!\nT W P\nhot sun 0.4\nhot rain 0.1\ncold sun 0.2\ncold rain 0.3\n'), Document(metadata={'source': 'Data\\AI-Lecture Note 6 Slides Version 1.pdf', 'page': 10}, page_content='Probabilistic Models\n\uf0a7 A probabilistic model is a joint distribution \nover a set of random variables\n\uf0a7 Probabilistic models:\n\uf0a7 (Random) variables with domains \n\uf0a7 Assignments are called outcomes\n\uf0a7 Joint distributions: say whether assignments \n(outcomes) are likely\n\uf0a7 Normalized: sum to 1.0\n\uf0a7 Ideally: only certain variables directly interact\n\uf0a7 Constraint satisfaction problems:\n\uf0a7 Variables with domains\n\uf0a7 Constraints: state whether assignments are \npossible\n\uf0a7 Ideally: only certain variables directly interact\nT W P\nhot sun 0.4\nhot rain 0.1\ncold sun 0.2\ncold rain 0.3\nT W P\nhot sun T\nhot rain F\ncold sun F\ncold rain T\nDistribution over T,W\nConstraint over T,W\n'), Document(metadata={'source': 'Data\\AI-Lecture Note 6 Slides Version 1.pdf', 'page': 11}, page_content='Events\n\uf0a7 An event is a set E of outcomes\n\uf0a7 From a joint distribution, we can \ncalculate the probability of any event\n\uf0a7 Probability that it’s hot AND sunny?\n\uf0a7 Probability that it’s hot?\n\uf0a7 Probability that it’s hot OR sunny?\n\uf0a7 Typically, the events we care about \nare partial assignments, like P(T=hot)\nT W P\nhot sun 0.4\nhot rain 0.1\ncold sun 0.2\ncold rain 0.3\n'), Document(metadata={'source': 'Data\\AI-Lecture Note 6 Slides Version 1.pdf', 'page': 12}, page_content='Quiz: Events\n\uf0a7 P(+x, +y) ?\n\uf0a7 P(+x) ?\n\uf0a7 P(-y OR +x) ?\nX Y P\n+x +y 0.2\n+x -y 0.3\n-x +y 0.4\n-x -y 0.1\n'), Document(metadata={'source': 'Data\\AI-Lecture Note 6 Slides Version 1.pdf', 'page': 13}, page_content='Marginal Distributions\n\uf0a7 Marginal distributions are sub-tables which eliminate variables \n\uf0a7 Marginalization (summing out): Combine collapsed rows by adding\nT W P\nhot sun 0.4\nhot rain 0.1\ncold sun 0.2\ncold rain 0.3\nT P\nhot 0.5\ncold 0.5\nW P\nsun 0.6\nrain 0.4\n'), Document(metadata={'source': 'Data\\AI-Lecture Note 6 Slides Version 1.pdf', 'page': 14}, page_content='Quiz: Marginal Distributions\nX Y P\n+x +y 0.2\n+x -y 0.3\n-x +y 0.4\n-x -y 0.1\nX P\n+x\n-x\nY P\n+y\n-y\n'), Document(metadata={'source': 'Data\\AI-Lecture Note 6 Slides Version 1.pdf', 'page': 15}, page_content='Conditional Probabilities\n\uf0a7 A simple relation between joint and conditional probabilities\n\uf0a7 In fact, this is taken as the definition of a conditional probability\nT W P\nhot sun 0.4\nhot rain 0.1\ncold sun 0.2\ncold rain 0.3\nP(b)P(a)\nP(a,b)\n'), Document(metadata={'source': 'Data\\AI-Lecture Note 6 Slides Version 1.pdf', 'page': 16}, page_content='Quiz: Conditional Probabilities\nX Y P\n+x +y 0.2\n+x -y 0.3\n-x +y 0.4\n-x -y 0.1\n\uf0a7 P(+x | +y) ?\n\uf0a7 P(-x | +y) ?\n\uf0a7 P(-y | +x) ?'), Document(metadata={'source': 'Data\\AI-Lecture Note 6 Slides Version 1.pdf', 'page': 17}, page_content='Conditional Distributions\n\uf0a7 Conditional distributions are probability distributions over \nsome variables given fixed values of others\nT W P\nhot sun 0.4\nhot rain 0.1\ncold sun 0.2\ncold rain 0.3\nW P\nsun 0.8\nrain 0.2\nW P\nsun 0.4\nrain 0.6\nConditional Distributions Joint Distribution\n'), Document(metadata={'source': 'Data\\AI-Lecture Note 6 Slides Version 1.pdf', 'page': 18}, page_content='Normalization Trick\nT W P\nhot sun 0.4\nhot rain 0.1\ncold sun 0.2\ncold rain 0.3\nW P\nsun 0.4\nrain 0.6\n'), Document(metadata={'source': 'Data\\AI-Lecture Note 6 Slides Version 1.pdf', 'page': 19}, page_content='SELECT the joint \nprobabilities \nmatching the \nevidence\nNormalization Trick\nT W P\nhot sun 0.4\nhot rain 0.1\ncold sun 0.2\ncold rain 0.3\nW P\nsun 0.4\nrain 0.6\nT W P\ncold sun 0.2\ncold rain 0.3\nNORMALIZE the \nselection\n(make it sum to one)'), Document(metadata={'source': 'Data\\AI-Lecture Note 6 Slides Version 1.pdf', 'page': 20}, page_content='Normalization Trick\nT W P\nhot sun 0.4\nhot rain 0.1\ncold sun 0.2\ncold rain 0.3\nW P\nsun 0.4\nrain 0.6\nT W P\ncold sun 0.2\ncold rain 0.3\nSELECT the joint \nprobabilities \nmatching the \nevidence\nNORMALIZE the \nselection\n(make it sum to one)\n\uf0a7 Why does this work? Sum of selection is P(evidence)!  (P(T=c), here)\n'), Document(metadata={'source': 'Data\\AI-Lecture Note 6 Slides Version 1.pdf', 'page': 21}, page_content='Quiz: Normalization Trick\nX Y P\n+x +y 0.2\n+x -y 0.3\n-x +y 0.4\n-x -y 0.1\nSELECT the joint \nprobabilities \nmatching the \nevidence\nNORMALIZE the \nselection\n(make it sum to one)\n\uf0a7 P(X | Y=-y) ?'), Document(metadata={'source': 'Data\\AI-Lecture Note 6 Slides Version 1.pdf', 'page': 22}, page_content='\uf0a7 (Dictionary) To bring or restore to a normal condition\n\uf0a7 Procedure:\n\uf0a7 Step 1: Compute Z = sum over all entries\n\uf0a7 Step 2: Divide every entry by Z\n\uf0a7 Example 1\nTo Normalize\nAll entries sum to ONE\nW P\nsun 0.2\nrain 0.3 Z = 0.5\nW P\nsun 0.4\nrain 0.6\n\uf0a7 Example 2\nT W P\nhot sun 20\nhot rain 5\ncold sun 10\ncold rain 15\nNormalize\nZ = 50\nNormalize\nT W P\nhot sun 0.4\nhot rain 0.1\ncold sun 0.2\ncold rain 0.3'), Document(metadata={'source': 'Data\\AI-Lecture Note 6 Slides Version 1.pdf', 'page': 23}, page_content='Probabilistic Inference\n\uf0a7 Probabilistic inference: compute a desired probability \nfrom other known probabilities (e.g. conditional from \njoint)\n\uf0a7 We generally compute conditional probabilities \n\uf0a7 P(airport on time | no reported accidents) = 0.90\n\uf0a7 These represent the agent’s beliefs given the evidence\n\uf0a7 Probabilities change with new evidence:\n\uf0a7 P(airport on time | no accidents, 5 a.m.) = 0.95\n\uf0a7 P(airport on time | no accidents, 5 a.m., raining) = 0.80\n\uf0a7 Observing new evidence causes beliefs to be updated'), Document(metadata={'source': 'Data\\AI-Lecture Note 6 Slides Version 1.pdf', 'page': 24}, page_content='Inference by Enumeration\n\uf0a7 General case:\n\uf0a7 Evidence variables: \n\uf0a7 Query* variable:\n\uf0a7 Hidden variables:\n All variables\n* Works fine with \nmultiple query \nvariables, too\n\uf0a7 We want:\n\uf0a7 Step 1: Select the \nentries consistent \nwith the evidence\n\uf0a7 Step 2: Sum out H to get joint \nof Query and evidence\n\uf0a7 Step 3: Normalize\n'), Document(metadata={'source': 'Data\\AI-Lecture Note 6 Slides Version 1.pdf', 'page': 25}, page_content='28'), Document(metadata={'source': 'Data\\AI-Lecture Note 6 Slides Version 1.pdf', 'page': 26}, page_content='29\n'), Document(metadata={'source': 'Data\\AI-Lecture Note 6 Slides Version 1.pdf', 'page': 27}, page_content='30\n'), Document(metadata={'source': 'Data\\AI-Lecture Note 6 Slides Version 1.pdf', 'page': 28}, page_content='31\n'), Document(metadata={'source': 'Data\\AI-Lecture Note 6 Slides Version 1.pdf', 'page': 29}, page_content='32\n'), Document(metadata={'source': 'Data\\AI-Lecture Note 6 Slides Version 1.pdf', 'page': 30}, page_content='33\n'), Document(metadata={'source': 'Data\\AI-Lecture Note 6 Slides Version 1.pdf', 'page': 31}, page_content='34\n'), Document(metadata={'source': 'Data\\AI-Lecture Note 6 Slides Version 1.pdf', 'page': 32}, page_content='Inference by Enumeration\n\uf0a7 P(W)?\n\uf0a7 P(W | winter)?\n\uf0a7 P(W | winter, hot)?\nS T W P\nsummer hot sun 0.30\nsummer hot rain 0.05\nsummer cold sun 0.10\nsummer cold rain 0.05\nwinter hot sun 0.10\nwinter hot rain 0.05\nwinter cold sun 0.15\nwinter cold rain 0.20'), Document(metadata={'source': 'Data\\AI-Lecture Note 6 Slides Version 1.pdf', 'page': 33}, page_content='\uf0a7 Obvious problems:\n\uf0a7 Worst-case time complexity O(dn) \n\uf0a7 Space complexity O(dn) to store the joint distribution\nInference by Enumeration'), Document(metadata={'source': 'Data\\AI-Lecture Note 6 Slides Version 1.pdf', 'page': 34}, page_content='The Product Rule\n\uf0a7 Sometimes have conditional distributions but want the joint\n'), Document(metadata={'source': 'Data\\AI-Lecture Note 6 Slides Version 1.pdf', 'page': 35}, page_content='The Product Rule\n\uf0a7 Example:\nR P\nsun 0.8\nrain 0.2\nD W P\nwet sun 0.1\ndry sun 0.9\nwet rain 0.7\ndry rain 0.3\nD W P\nwet sun 0.08\ndry sun 0.72\nwet rain 0.14\ndry rain 0.06\n'), Document(metadata={'source': 'Data\\AI-Lecture Note 6 Slides Version 1.pdf', 'page': 36}, page_content='The Chain Rule\n\uf0a7 More generally, can always write any joint distribution as an \nincremental product of conditional distributions\n\uf0a7 Why is this always true?\n'), Document(metadata={'source': 'Data\\AI-Lecture Note 6 Slides Version 1.pdf', 'page': 37}, page_content='Bayes Rule\n'), Document(metadata={'source': 'Data\\AI-Lecture Note 6 Slides Version 1.pdf', 'page': 38}, page_content='Bayes’ Rule\n\uf0a7 Two ways to factor a joint distribution over two variables:\n\uf0a7 Dividing, we get:\n\uf0a7 Why is this at all helpful?\n\uf0a7 Lets us build one conditional from its reverse\n\uf0a7 Often one conditional is tricky but the other one is simple\n\uf0a7 Foundation of many systems we’ll see later (e.g. ASR, MT)\n\uf0a7 In the running for most important AI equation!\nThat’s my rule!'), Document(metadata={'source': 'Data\\AI-Lecture Note 6 Slides Version 1.pdf', 'page': 39}, page_content='Inference with Bayes’ Rule\n\uf0a7 Example: Diagnostic probability from causal probability:\n\uf0a7 Example:\n\uf0a7 M: meningitis, S: stiff neck\n\uf0a7 Note: posterior probability of meningitis still very small\n\uf0a7 Note: you should still get stiff necks checked out!  Why?\n'), Document(metadata={'source': 'Data\\AI-Lecture Note 6 Slides Version 1.pdf', 'page': 40}, page_content='Quiz: Bayes’ Rule\n\uf0a7 Given:\n\uf0a7 What is P(W | dry) ? \nR P\nsun 0.8\nrain 0.2\nD W P\nwet sun 0.1\ndry sun 0.9\nwet rain 0.7\ndry rain 0.3\n'), Document(metadata={'source': 'Data\\AI-Lecture Note 6 Slides Version 1.pdf', 'page': 41}, page_content='Ghostbusters, Revisited\n\uf0a7 Let’s say we have two distributions:\n\uf0a7 Prior distribution over ghost location: P(G)\n\uf0a7 Let’s say this is uniform\n\uf0a7 Sensor reading model: P(R | G)\n\uf0a7 Given: we know what our sensors do\n\uf0a7 R = reading color measured at (1,1)\n\uf0a7 E.g. P(R = yellow | G=(1,1)) = 0.1\n\uf0a7 We can calculate the posterior \ndistribution P(G|r) over ghost locations \ngiven a reading using Bayes’ rule:\n[Demo: Ghostbuster – with probability (L12D2) ]'), Document(metadata={'source': 'Data\\AI-Lecture Note 6 Slides Version 1.pdf', 'page': 42}, page_content='Video of Demo Ghostbusters with Probability\n'), Document(metadata={'source': 'Data\\AI-Lecture Note 6 Slides Version 2.pdf', 'page': 0}, page_content='Bayes’ Nets\n[These slides were created by Dan Klein and Pieter Abbeel for CS188 Intro to AI at UC Berkeley.  All CS188 materials are available at http://ai.berkeley.edu.]'), Document(metadata={'source': 'Data\\AI-Lecture Note 6 Slides Version 2.pdf', 'page': 1}, page_content='Probabilistic Models\n\uf0a7 Models describe how (a portion of) the world works\n\uf0a7 Models are always simplifications\n\uf0a7 May not account for every variable\n\uf0a7 May not account for all interactions between variables\n\uf0a7 “All models are wrong; but some are useful.”\n– George E. P. Box\n\uf0a7 What do we do with probabilistic models?\n\uf0a7 We (or our agents) need to reason about unknown \nvariables, given evidence\n\uf0a7 Example: explanation (diagnostic reasoning)\n\uf0a7 Example: prediction (causal reasoning)\n\uf0a7 Example: value of information'), Document(metadata={'source': 'Data\\AI-Lecture Note 6 Slides Version 2.pdf', 'page': 2}, page_content='Independence\n'), Document(metadata={'source': 'Data\\AI-Lecture Note 6 Slides Version 2.pdf', 'page': 3}, page_content='\uf0a7 Two variables are independent if:\n\uf0a7 This says that their joint distribution factors into a product two \nsimpler distributions\n\uf0a7 Another form:\n\uf0a7 We write: \n\uf0a7 Independence is a simplifying modeling assumption\n\uf0a7 Empirical joint distributions: at best “close” to independent\n\uf0a7 What could we assume for {Weather, Traffic, Cavity, Toothache}?\nIndependence\n'), Document(metadata={'source': 'Data\\AI-Lecture Note 6 Slides Version 2.pdf', 'page': 4}, page_content='Example: Independence?\nT W P\nhot sun 0.4\nhot rain 0.1\ncold sun 0.2\ncold rain 0.3\nT W P\nhot sun 0.3\nhot rain 0.2\ncold sun 0.3\ncold rain 0.2\nT P\nhot 0.5\ncold 0.5\nW P\nsun 0.6\nrain 0.4\n'), Document(metadata={'source': 'Data\\AI-Lecture Note 6 Slides Version 2.pdf', 'page': 5}, page_content='Example: Independence\n\uf0a7 N fair, independent coin flips:\nH 0.5\nT 0.5\nH 0.5\nT 0.5\nH 0.5\nT 0.5\n'), Document(metadata={'source': 'Data\\AI-Lecture Note 6 Slides Version 2.pdf', 'page': 6}, page_content="Conditional Independence\n\uf0a7 P(Toothache, Cavity, Catch)\n\uf0a7 If I have a cavity, the probability that the probe catches in it \ndoesn't depend on whether I have a toothache:\n\uf0a7 P(+catch | +toothache, +cavity) = P(+catch | +cavity)\n\uf0a7 The same independence holds if I don’t have a cavity:\n\uf0a7 P(+catch | +toothache, -cavity) = P(+catch| -cavity)\n\uf0a7 Catch is conditionally independent of Toothache given Cavity:\n\uf0a7 P(Catch | Toothache, Cavity) = P(Catch | Cavity)\n\uf0a7 Equivalent statements:\n\uf0a7 P(Toothache | Catch , Cavity) = P(Toothache | Cavity)\n\uf0a7 P(Toothache, Catch | Cavity) = P(Toothache | Cavity) P(Catch | Cavity)\n\uf0a7 One can be derived from the other easily"), Document(metadata={'source': 'Data\\AI-Lecture Note 6 Slides Version 2.pdf', 'page': 7}, page_content='Conditional Independence\n\uf0a7 Unconditional (absolute) independence very rare (why?)\n\uf0a7 Conditional independence is our most basic and robust form \nof knowledge about uncertain environments.\n\uf0a7 X is conditionally independent of Y given Z\nif and only if:\nor, equivalently, if and only if\n'), Document(metadata={'source': 'Data\\AI-Lecture Note 6 Slides Version 2.pdf', 'page': 8}, page_content='Conditional Independence\n\uf0a7 What about this domain:\n\uf0a7 Traffic\n\uf0a7 Umbrella\n\uf0a7 Raining\n'), Document(metadata={'source': 'Data\\AI-Lecture Note 6 Slides Version 2.pdf', 'page': 9}, page_content='Conditional Independence\n\uf0a7 What about this domain:\n\uf0a7 Fire\n\uf0a7 Smoke\n\uf0a7 Alarm\n'), Document(metadata={'source': 'Data\\AI-Lecture Note 6 Slides Version 2.pdf', 'page': 10}, page_content='Conditional Independence and the Chain Rule\n\uf0a7 Chain rule: \n\uf0a7 Trivial decomposition:\n\uf0a7 With assumption of conditional independence:\n\uf0a7 Bayes’nets / graphical models help us express conditional independence assumptions\n'), Document(metadata={'source': 'Data\\AI-Lecture Note 6 Slides Version 2.pdf', 'page': 11}, page_content='Inference in Ghostbusters\n\uf0a7 A ghost is in the grid \nsomewhere\n\uf0a7 Sensor readings tell how \nclose a square is to the \nghost\n\uf0a7 On the ghost: red\n\uf0a7 1 or 2 away: orange\n\uf0a7 3 or 4 away: yellow\n\uf0a7 5+ away: green\n'), Document(metadata={'source': 'Data\\AI-Lecture Note 6 Slides Version 2.pdf', 'page': 12}, page_content='Video of Demo Ghostbusters with Probability\n'), Document(metadata={'source': 'Data\\AI-Lecture Note 6 Slides Version 2.pdf', 'page': 13}, page_content='15\n'), Document(metadata={'source': 'Data\\AI-Lecture Note 6 Slides Version 2.pdf', 'page': 14}, page_content='16\n'), Document(metadata={'source': 'Data\\AI-Lecture Note 6 Slides Version 2.pdf', 'page': 15}, page_content='17\n'), Document(metadata={'source': 'Data\\AI-Lecture Note 6 Slides Version 2.pdf', 'page': 16}, page_content='Bayes’Nets: Big Picture\n'), Document(metadata={'source': 'Data\\AI-Lecture Note 6 Slides Version 2.pdf', 'page': 17}, page_content='Bayes’ Nets: Big Picture\n\uf0a7 Two problems with using full joint distribution tables \nas our probabilistic models:\n\uf0a7 Unless there are only a few variables, the joint is WAY too \nbig to represent explicitly\n\uf0a7 Hard to learn (estimate) anything empirically about more \nthan a few variables at a time\n\uf0a7 Bayes’ nets: a technique for describing complex joint \ndistributions (models) using simple, local \ndistributions (conditional probabilities)\n\uf0a7 More properly called graphical models\n\uf0a7 We describe how variables locally interact\n\uf0a7 Local interactions chain together to give global, indirect \ninteractions\n\uf0a7 For about 10 min, we’ll be vague about how these \ninteractions are specified\n'), Document(metadata={'source': 'Data\\AI-Lecture Note 6 Slides Version 2.pdf', 'page': 18}, page_content='Graphical Model Notation\n\uf0a7 Nodes: variables (with domains)\n\uf0a7 Can be assigned (observed) or unassigned \n(unobserved)\n\uf0a7 Arcs: interactions\n\uf0a7 Similar to CSP constraints\n\uf0a7 Indicate “direct influence” between variables\n\uf0a7 Formally: encode conditional independence \n(more later)\n\uf0a7 For now: imagine that arrows mean \ndirect causation (in general, they don’t!)\n'), Document(metadata={'source': 'Data\\AI-Lecture Note 6 Slides Version 2.pdf', 'page': 19}, page_content='Example: Coin Flips\n\uf0a7 N independent coin flips\n\uf0a7 No interactions between variables: absolute independence\nX1 X2 Xn\n'), Document(metadata={'source': 'Data\\AI-Lecture Note 6 Slides Version 2.pdf', 'page': 20}, page_content=''), Document(metadata={'source': 'Data\\AI-Lecture Note 6 Slides Version 2.pdf', 'page': 21}, page_content=''), Document(metadata={'source': 'Data\\AI-Lecture Note 6 Slides Version 2.pdf', 'page': 22}, page_content=''), Document(metadata={'source': 'Data\\AI-Lecture Note 6 Slides Version 2.pdf', 'page': 23}, page_content=''), Document(metadata={'source': 'Data\\AI-Lecture Note 6 Slides Version 2.pdf', 'page': 24}, page_content=''), Document(metadata={'source': 'Data\\AI-Lecture Note 6 Slides Version 2.pdf', 'page': 25}, page_content='Bayes’ Net Semantics\n'), Document(metadata={'source': 'Data\\AI-Lecture Note 6 Slides Version 2.pdf', 'page': 26}, page_content=''), Document(metadata={'source': 'Data\\AI-Lecture Note 6 Slides Version 2.pdf', 'page': 27}, page_content='Example: Alarm Network\n\uf0a7 Variables\n\uf0a7 B: Burglary\n\uf0a7 E: Earthquake\n\uf0a7 A: Alarm goes off\n\uf0a7 M: Mary calls\n\uf0a7 J: John calls\n'), Document(metadata={'source': 'Data\\AI-Lecture Note 6 Slides Version 2.pdf', 'page': 28}, page_content=''), Document(metadata={'source': 'Data\\AI-Lecture Note 6 Slides Version 2.pdf', 'page': 29}, page_content=''), Document(metadata={'source': 'Data\\AI-Lecture Note 6 Slides Version 2.pdf', 'page': 30}, page_content='33'), Document(metadata={'source': 'Data\\AI-Lecture Note 6 Slides Version 2.pdf', 'page': 31}, page_content='34\n'), Document(metadata={'source': 'Data\\AI-Lecture Note 6 Slides Version 2.pdf', 'page': 32}, page_content='35'), Document(metadata={'source': 'Data\\AI-Lecture Note 6 Slides Version 2.pdf', 'page': 33}, page_content=''), Document(metadata={'source': 'Data\\AI-Lecture Note 6 Slides Version 2.pdf', 'page': 34}, page_content=''), Document(metadata={'source': 'Data\\AI-Lecture Note 6 Slides Version 2.pdf', 'page': 35}, page_content='38'), Document(metadata={'source': 'Data\\AI-Lecture Note 6 Slides Version 2.pdf', 'page': 36}, page_content='Example: Traffic\nR\nT\n+r 1/4\n-r 3/4\n+r +t 3/4\n-t 1/4\n-r +t 1/2\n-t 1/2\n'), Document(metadata={'source': 'Data\\AI-Lecture Note 6 Slides Version 2.pdf', 'page': 37}, page_content='Example: Traffic\n\uf0a7 Causal direction\nR\nT\n+r 1/4\n-r 3/4\n+r +t 3/4\n-t 1/4\n-r +t 1/2\n-t 1/2\n+r +t 3/16\n+r -t 1/16\n-r +t 6/16\n-r -t 6/16\n'), Document(metadata={'source': 'Data\\AI-Lecture Note 6 Slides Version 2.pdf', 'page': 38}, page_content='Example: Reverse Traffic\n\uf0a7 Reverse causality?\nT\nR\n+t 9/16\n-t 7/16\n+t +r 1/3\n-r 2/3\n-t +r 1/7\n-r 6/7\n+r +t 3/16\n+r -t 1/16\n-r +t 6/16\n-r -t 6/16\n'), Document(metadata={'source': 'Data\\AI-Lecture Note 6 Slides Version 2.pdf', 'page': 39}, page_content='Causality?\n\uf0a7 When Bayes’ nets reflect the true causal patterns:\n\uf0a7 Often simpler (nodes have fewer parents)\n\uf0a7 Often easier to think about\n\uf0a7 Often easier to elicit from experts\n\uf0a7 BNs need not actually be causal\n\uf0a7 Sometimes no causal net exists over the domain \n(especially if variables are missing)\n\uf0a7 E.g. consider the variables Traffic and Drips\n\uf0a7 End up with arrows that reflect correlation, not causation\n\uf0a7 What do the arrows really mean?\n\uf0a7 Topology may happen to encode causal structure\n\uf0a7 Topology really encodes conditional independence\n'), Document(metadata={'source': 'Data\\AI-Lecture Note 6 Slides Version 2.pdf', 'page': 40}, page_content='43'), Document(metadata={'source': 'Data\\AI-Lecture Note 6.pdf', 'page': 0}, page_content='CS 188 Introduction to Artiﬁcial Intelligence\nFall 2018 Note 6\nThese lecture notes are heavily based on notes originally written by Josh Hug and Jacky Liang.\nProbabilistic Inference\nIn artiﬁcial intelligence, we often want to model the relationships between various nondeterministic events.\nIf the weather predicts a 40% chance of rain, should I carry my umbrella? How many scoops of ice cream\nshould I get if the more scoops I get, the more likely I am to drop it all? If there was an accident 15 minutes\nago on the freeway on my route to Oracle Arena to watch the Warriors’ game, should I leave now or in 30\nminutes? All of these questions (and innumerable more) can be answered withprobabilistic inference.\nWe’re assuming that you’ve learned the foundations of probability in CS70, so these notes will not review\nbasic concepts of probability like PDFs, conditional probabilities, independence, and conditional indepen-\ndence.\nIn previous sections of this class, we modeled the world as existing in a speciﬁc state that is always known.\nFor the next several weeks, we will instead use a new model where each possible state for the world has\nits own probability. For example, we might build a weather model, where the state consists of the season,\ntemperature and weather. Our model might say thatP(winter, 35\x00, cloudy)= 0.023. This number represents\nthe probability of the speciﬁc outcome that it is winter, 35\x00, and cloudy.\nMore precisely, our model is ajoint distribution, i.e. a table of probabilities which captures the likelihood\nof each possibleoutcome, also known as anassignment. As an example, consider the table below:\nSeason Temperature Weather Probability\nsummer hot sun 0.30\nsummer hot rain 0.05\nsummer cold sun 0.10\nsummer cold rain 0.05\nwinter hot sun 0.10\nwinter hot rain 0.05\nwinter cold sun 0.15\nwinter cold rain 0.20\nThis model allows us to answer questions that might be of interest to us, for example:\n• What is the probability that it is sunny?P(W = sun)\n• What is the probability distribution for the weather, given that we know it is winter?P(W | S = winter)\n• What is the probability that it is winter, given that we know it is rainy and cold?P(S = winter | T =\ncold,W = rain)\n• What is the probability distribution for the weather and season give that we know that it is cold?\nP(S,W | T = cold)\nCS 188, Fall 2018, Note 6 1'), Document(metadata={'source': 'Data\\AI-Lecture Note 6.pdf', 'page': 1}, page_content='Given a joint PDF, we can trivially perform compute any desired probablity distributionP(Q1 ... Qk | e1 ... ek)\nusing a simple and intuitive procedure known asinference by enumeration, for which we deﬁne three types\nof variables we will be dealing with:\n1. Query variablesQi, which are unknown and appear on the left side of the probability distribution we\nare trying to compute.\n2. Evidence variablesei, which are observed variables whose values are known and appear on the right\nside of the probability distribution we are trying to compute.\n3. Hidden variables, which are values present in the overall joint distribution but not in the distribution\nwe are currently trying to compute.\nIn this procedure, we collect all the rows consistent with the observed evidence variables, sum out all the\nhidden variables, and ﬁnally normalize the table so that it is a probability distribution (i.e. values sum to 1).\nFor example, if we wanted to computeP(W | S = winter), we’d select the four rows whereS is winter, then\nsum out overT and normalize. This yields the following probability table:\nW S Unnormalized Sum Probability\nsun winter 0.10+0.15 = 0.25 0.25/(0.25+0.25)= 0.5\nrain winter 0.05+0.20 = 0.25 0.25/(0.25+0.25)= 0.5\nHence P(W = sun | S = winter)= 0.5 andP(W = rain | S = winter)= 0.5, and we learn that in winter\nthere’s a 50% chance of sun and a 50% chance of rain (classic California weather).\nSo long as we have the joint PDF table, inference by enumeration (IBE) can be used to compute any desired\nprobablity distribution, even for multiple query variablesQ1...Qk.\nBayes Nets (Representation)\nWhile inference by enumeration can compute probabilities for any query we might desire, representing an\nentire joint distribution in the memory of a computer is impractical for real problems - if each ofn variables\nwe wish to represent can take ond possible values (it has adomain of sized), then our joint distribution\ntable will havedn entries, exponential in the number of variables and quite impractical to store!\nBayes nets avoid this issue by taking advantage of the idea of conditional probability. Rather than storing\ninformation in a giant table, probabilities are instead distributed across a large number of smaller local\nprobability tables along with adirected acyclic graph(DAG) which captures the relationships between\nvariables. The local probability tables and the DAG together encode enough information to compute any\nprobability distribution that we could have otherwise computed given the entire joint distribution.\nSpeciﬁcally, each node in the graph represents a single random variable and each directed edge represents\none of the conditional probability distributions we choose to store (i.e. an edge from nodeA to nodeB\nindicates that we store the probability table forP(B|A)). Each node is conditionally independent of all its\nancestor nodes in the graph, given all of its parents. Thus, if we have a node representing variableX, we\nstore P(X|A1,A2,. . . ,AN), whereA1,. . . ,AN are the parents ofX.\nAs an example of a Bayes Net, consider a model where we have ﬁve binary random variables described\nbelow:\nCS 188, Fall 2018, Note 6 2'), Document(metadata={'source': 'Data\\AI-Lecture Note 6.pdf', 'page': 2}, page_content='• B: Burglary occurs.\n• A: Alarm goes off.\n• E: Earthquake occurs.\n• J: John calls.\n• M: Mary calls.\nAssume the alarm can go off if either a burglary or an earthquake occurs, and that Mary and John will call\nif they hear the alarm. We can represent these dependencies with the graph shown below.\nAs a reality check, it’s important to internalize that Bayes Nets are only a type of model. Models attempt\nto capture the way the world works, but because they are always a simpliﬁcation they are always wrong.\nHowever, with good modeling choices they can still be good enough approximations that they are useful for\nsolving real problems in the real world. In general, they will not account for every variable or even every\ninteraction between variables.\nReturning to our discussion, we formally deﬁne a Bayes Net as consisting of:\n• A directed acyclic graph of nodes, one per variableX.\n• A conditional distribution for each nodeP(X|A1 ... An), whereAi is theith parent ofX, stored as a\nconditional probability tableor CPT. Each CPT hasn+2 columns: one for the values of each of the\nn parent variablesA1 ... An, one for the values ofX, and one for the conditional probability ofX.\nIn the alarm model above, we would store probability tablesP(B),P(E),P(A | B,E),P(J | A) and P(M | A).\nGiven all of the CPTs for a graph, we can calculate the probability of a given assignment using the chain\nrule: P(X1,X2,..., Xn)= ’n\ni=1 P(Xi|parents(Xi)).\nFor the alarm model above, we might calculate the probability of one event as follows:P(\x00b,\x00e,+a,+ j,\x00m)=\nP(\x00b) · P(\x00e) · P(+a|\x00 b,\x00e) · P(+j| +a) · P(\x00m| +a).\nCS 188, Fall 2018, Note 6 3'), Document(metadata={'source': 'Data\\AI-Lecture Note 6.pdf', 'page': 3}, page_content='This works because of the conditional independence relationships given by the graph. Speciﬁcally, we rely\non the fact thatP(xi|x1,..., xi\x001)= P(xi|parents(Xi)). Or in other words, that the probability of a speciﬁc\nvalue ofXi depends only on the values assigned toXi’s parents.\nBayes Nets (Inference)\nInference is the process of calculating the joint PDF for some set of query variables based on some set\nof observed variables. We can solve this problem naively by forming the joint PDF and using inference by\nenumeration as described above. This requires the creation of and iteration over an exponentially large table.\nAn alternate approach is toeliminate variables one by one. To eliminate a variableX, we:\n1. Join (multiply together) all factors involvingX.\n2. Sum outX.\nA factor is deﬁned simply as anunnormalized probability. At all points during variable elimination, each\nfactor will be proportional to the probability it corresponds to but the underlying distribution for each factor\nwon’t necessarily sum to 1 as a probability distribution should.\nLet’s make these ideas more concrete with an example. Suppose we have a model as shown below, where\nT, C, S, andE can take on binary values, as shown below. Here,T represents the chance that an adventurer\ntakes a treasure,C represents the chance that a cage falls on the adventurer given that he takes the treasure,\nS represents the chance that snakes are released if an adventurer takes the treasure, andE represents the\nchance that the adventurer escapes given information about the status of the cage and snakes.\nIn this case, we have the factorsP(T), P(C|T), P(S|T), and P(E|C,S). Suppose we want to calculate\nP(T| + e). The inference by enumeration approach would be to form the 16 row joint PDFP(T,C,S,E),\nselect only the rows corresponding to +e, then summing outC and S and ﬁnally normalizing.\nThe alternate approach is to eliminateC, thenS, one variable at a time. We’d proceed as follows:\n• Join (multiply) all the factors involvingC, formingP(C,+e|T,S)= P(C|T) · P(+e|C,S).\n• Sum outC from this new factor, leaving us with a new factorP(+e|T,S).\n• Join all factors involvingS, formingP(+e,S|T)= P(S|T) · P(+e|T,S).\nCS 188, Fall 2018, Note 6 4'), Document(metadata={'source': 'Data\\AI-Lecture Note 6.pdf', 'page': 4}, page_content='• Sum outS, yieldingP(+e|T).\nOnce we haveP(+e|T), we can easily computeP(T| +e).\nWhile this process is more involved from a conceptual point of view, the maximum size of any factor\ngenerated is only 8 rows instead of 16 as it would be if we formed the entire joint PDF.\nAn alternate way of looking at the problem is to observe that the calculation ofP(+e,T) can either be done,\nas it is in inference by enumeration, as follows:\nÂs\nÂc\nP(T)P(s|T)P(c|T)P(+e|c,s)\nVariable elimination is equivalent to calculatingP(+e,T) as follows:\nP(T)Âs\nP(s|T)Âc\nP(c|T)P(+e|c,s)\nBayes Nets (Sampling)\nAn alternate approach for probabilistic reasoning is to implicitly calculate the probabilities for our query by\nsimply counting samples.\nFor example, suppose we wanted to calculateP(T| + e). If we had a magic machine that could generate\nsamples from our distribution, we could collect all samples for which the adventurer escapes the maze, and\nthen compute the fraction of those escapes for which the adventurer also took the treasure. Put differently,\nif we could run simulations of say, a few million adventurers, we’d easily be able to compute any inference\nwe’d want just by looking at the samples.\nGiven a Bayes Net model, we can easily write a simulator. For example, consider the CPTs given below for\nthe simpliﬁed model with only two variables T and C.\nCS 188, Fall 2018, Note 6 5'), Document(metadata={'source': 'Data\\AI-Lecture Note 6.pdf', 'page': 5}, page_content='A simple simulator in Python would be as follows:\nimport random\ndef get_t():\nif random.random() < 0.99:\nreturn True\nreturn False\ndef get_c(t):\nif t and random.random() < 0.95:\nreturn True\nreturn False\ndef get_sample():\nt = get_t()\nc = get_c(t)\nreturn [t, c]\nWe call this simple approachprior sampling. The downside of this approach is that it may require the\ngeneration of a very large number of samples in order to perform analysis of unlikely scenarios. If we\nwanted to computeP(C|\x00 t), we’d have to throw away 99% of our samples.\nOne way to mitigate this this problem, we can modify our procedure to early reject any sample inconsistent\nwith our evidence. For example, for the queryP(C|\x00 t), we’d avoid generating a value for C unless t is true.\nThis still means we have to throw away most of our samples, but at least the bad samples we generate take\nless time to create. We call this approachrejection sampling.\nThese two approaches work for the same reason, which is that any valid sample occurs with the same\nprobability as speciﬁed in the joint PDF. In other words, the probability of every sample is based on the\nproduct of every CPT, or as I personally call it, the "every CPT participates principle".\nA more exotic approach islikelihood weighting, which ensures that we never generate a bad sample. In\nthis approach, we manually set all variables equal to the evidence in our query. For example, if we wanted\nto computeP(C|\x00 t), we’d simply declare that t is false. The problem here is that this may yield samples\nthat are inconsistent with the correct distribution. As an example, consider the more complex four variable\nmodel for T, C, S, and E given earlier in these notes. If we wanted to computeP(T,S,+c,+e), and simply\npicked values for T and S without taking into account the fact that c = false, and e = true, then there’s no\nguarantee that our samples actually obey the joint PDF given by the Bayes Net. For example, if the cage\nonly ever falls if the treasure is taken, then we’d want to ensure that T is always true instead of using the\nP(T) distribution given in the Bayes Net.\nPut differently, if we simply force some variables equal to the evidence, then our samples occur with proba-\nbility given only equal to the products of the CPTs of the non-evidence variables. This means the joint PDF\nhas no guarantee of being correct (though may be for some cases like our two variable Bayes Net). Instead,\nif we have sampled variablesZ1 through Zp and ﬁxed evidence variablesE1 through Em a sample is given\nby the probabilityP(Z1...Zp,E1...Em)= ’p\ni P(Zi)|Parents(Zi). What is missing is that the probability of a\nsample does not include all the probabilities ofP(Ei|Parents(Ei)), i.e. not every CPT participates.\nLikelihood weighting solves this issue by using a weight for each sample, which is the probability of the\nevidence variables given the sampled variables. That is, instead of counting all samples equally, we can\nCS 188, Fall 2018, Note 6 6'), Document(metadata={'source': 'Data\\AI-Lecture Note 6.pdf', 'page': 6}, page_content='deﬁne a weightwj for samplej that reﬂects how likely the observed values for the evidence variables are,\ngiven the sampled values. In this way, we ensure that every CPT participates. To do this, we iterate through\neach variable in the Bayes net, as we do for normal sampling), sampling a value if the variable is not an\nevidence variable, or changing the weight for the sample if the variable is evidence.\nFor example, suppose we want to calculateP(T| + c,+e). For thejth sample, we’d perform the following\nalgorithm:\n• Set wj to 1.0, andc = true ande = true.\n• For T: This is not an evidence variable, so we sampletj from P(T).\n• For C: This is an evidence variable, so we multiply the weight of the sample byP(+c|tj), i.e.wj =\nwj · P(+c|tj).\n• For S: samplesj from P(S | tj).\n• For E: multiply the weight of the sample byP(+e| +c,sj), i.e.wj = wj · P(+e| +c,sj).\nThen when we perform the usual counting process, we weight samplej by wj instead of 1, where 0<=\nwj <= 1. This approach works because in the ﬁnal calculations for the probabilities, the weights effectively\nserve to replace the missing CPTs. In effect, we ensure that the weighted probability of each sample is given\nby P(z1...zp,e1...em)=[ ’p\ni P(zi | Parents(zi))]· [’m\ni P(ei) | Parents(ei))].\nFor all three of our sampling methods (prior sampling, rejection sampling, and likelihod weighting), we\ncan get increasing amounts of accuracy by generating additional samples. However, of the three, likelihood\nweighting is the most computationally efﬁcient, for reasons beyond the scope of this course.\nGibbs Sampling is a fourth approach for sampling. In this approach, we ﬁrst set all variables to some totally\nrandom value (not taking into account any CPTs). We then repeatedly pick one variable at a time, clear its\nvalue, and resample it given the values currently assigned to all other variables.\nFor theT,C,S,E example above, we might assign t = true, c = true, s = false, and e = true. We then pick\none of our four variables to resample, sayS, and clear it. We then pick a new variable from the distribution\nP(S| + t,+c,+e). This requires us knowing this conditional distribution. It turns out that we can easily\ncompute the distribution of any single variable given all other variables. More speciﬁcally,P(S|T,C,E) can\nbe calculated only using the CPTs that connect S with its neighbors. Thus, in a typical Bayes Net, where\nmost variables have only a small number of neighbors, we can precompute the conditional distributions for\neach variable given all of its neighbors in linear time.\nWe will not prove this, but if we repeat this process enough times, our later samples will eventually converge\nto the correct distribution even though we may start from a low-probability assignment of values. If you’re\ncurious, there are some caveats beyond the scope of the course that you can read about under the Failure\nModes section of the Wikipedia article for Gibbs Sampling.\nBayes Nets (D-Separation)\nOne useful question to ask about a set of random variables is whether or not one variable is independent from\nanother, or if one random variable is conditionally independent of another given a third random variable.\nBayes’ Nets representation of joint probability distributions gives us a way to quickly answer such questions\nby inspecting the topological structure of the graph.\nCS 188, Fall 2018, Note 6 7'), Document(metadata={'source': 'Data\\AI-Lecture Note 6.pdf', 'page': 7}, page_content='We already mentioned thata node is conditionally independent of all its ancestor nodes in the graph\ngiven all of its parents.\nWe will present all three canonical cases of connected three-node two-edge Bayes’ Nets, or triples, and the\nconditional independence relationships they express.\nCausal Chains\nFigure 1: Causal Chain with no observations.\n Figure 2: Causal Chain withY observed.\nFigure 1 is a conﬁguration of three nodes known as acausal chain. It expresses the following representation\nof the joint distribution overX, Y, andZ:\nP(x,y,z)= P(z|y)P(y|x)P(x)\nIt’s important to note thatX and Z are not guaranteed to be independent, as shown by the following coun-\nterexample:\nP(y|x)=\n(\n1 if x = y\n0 else P(z|y)=\n(\n1 if z = y\n0 else\nIn this case,P(z|x)= 1 ifx = z and 0 otherwise, soX and Z are not independent.\nHowever, we can make the statement thatX ??Z | Y, as in Figure 2. Recall that this conditional indepdence\nmeans:\nP(X|Z,Y)= P(X|Y)\nWe can prove this statement as follows:\nP(X|Z,y)= P(X,Z,y)\nP(Z,y) = P(Z|y)P(y|X)P(X)\nÂx P(X,y,Z) = P(Z|y)P(y|X)P(X)\nP(Z|y)Âx P(y|x)P(x)\n= P(y|X)P(X)\nÂx P(y|x)P(x) = P(y|X)P(X)\nP(y) = P(X|y)\nAn analogous proof can be used to show the same thing for the case whereX has multiple parents. To\nsummarize, in the causal chain chain conﬁguration,X ??Z | Y.\nCommon Cause\nAnother possible conﬁguration for a triple is thecommon cause. It expresses the following representation:\nP(x,y,z)= P(x|y)P(z|y)P(y)\nJust like with causal chain, we can show thatX is not guaranteed to be independent ofZ with the following\ncounterexample distribution:\nCS 188, Fall 2018, Note 6 8'), Document(metadata={'source': 'Data\\AI-Lecture Note 6.pdf', 'page': 8}, page_content='Figure 3: Common Cause with no observations.\n Figure 4: Common Cause withY observed.\nP(x|y)=\n(\n1 if x = y\n0 else P(z|y)=\n(\n1 if z = y\n0 else\nThen P(x|z)= 1 ifx = z and 0 otherwise, soX and Z are not independent.\nBut it is true thatX ??Z | Y. That is,X and Z are independent ifY is observed as in Figure 4. We can show\nthis as follows:\nP(X|Z,y)= P(X,Z,y)\nP(Z,y) = P(X|y)P(Z|y)P(y)\nP(Z|y)P(y) = P(X|y)\nCommon E↵ect\nThe ﬁnal possible conﬁguration for a triple is thecommon effect, as shown in the ﬁgures below.\nFigure 5: Common Effect with no observations.\n Figure 6: Common Effect withY observed.\nIt expresses the representation:\nP(x,y,z)= P(y|x,z)P(x)P(z)\nIn the conﬁguration shown in Figure 5,X and Z are independent:X ??Z. However, they are not necessarily\nindependent when conditioned onY (Figure 6). As an example, suppose all three are binary variables.X\nCS 188, Fall 2018, Note 6 9'), Document(metadata={'source': 'Data\\AI-Lecture Note 6.pdf', 'page': 9}, page_content='and Z are true and false with equal probability:\nP(X = true)= P(X = f alse)= 0.5\nP(Z = true)= P(Z = f alse)= 0.5\nand Y is determined by whetherX and Z have the same value:\nP(Y|X,Z)=\n8\n><\n>:\n1 if X = Z and Y = true\n1 if X 6= Z and Y = f alse\n0 else\nThen X and Z are independent ifY is unobserved. But ifY is observed, then knowingX will tell us the value\nof Z, and vice-versa. SoX and Z are not conditionally independent givenY.\nCommon Effect can be viewed as “opposite” to Causal Chains and Common Cause –X and Z are guaranteed\nto be independent ifY is not conditioned on. But when conditioned onY, X and Z may be dependent\ndepending on the speciﬁc probability values forP(Y | X,Z)).\nThis same logic applies when conditioning on descendents ofY in the graph. If one ofY’s descendent nodes\nis observed, as in Figure 7,X and Z are not guaranteed to be independent.\nFigure 7: Common Effect with child observations.\nGeneral Case, and D-separation\nWe can use the previous three cases as building blocks to help us answer conditional independence questions\non an arbitrary Bayes’ Net with more than three nodes and two edges. We formulate the problem as follows:\nGiven a Bayes NetG, two nodesX andY, and a (possibly empty) set of nodes{Z1,... Zk} that represent\nobserved variables, must the following statement be true:X ??Y|{Z1,... Zk}?\nD-separation (directed separation) is a property of the structure of the Bayes Net graph that implies this\nconditional independence relationship, and generalizes the cases we’ve seen above. If a set of variables\nZ1,··· Zk d-separates X and Y, thenX ??Y |{ Z1,··· Zk} in all possible distributions that can be encoded by\nthe Bayes net.\nCS 188, Fall 2018, Note 6 10'), Document(metadata={'source': 'Data\\AI-Lecture Note 6.pdf', 'page': 10}, page_content='We start with an algorithm that is based on a notion of reachability from nodeX to nodeY.( Note: this\nalgorithm is not quite correct! We’ll see how to ﬁx it in a moment.)\n1. Shade all observed nodes{Z1,... Zk} in the graph.\n2. If there exists an undirected path fromX and Y that is not blocked by a shaded node,X and Y are\n“connected”.\n3. If X and Y are connected, they’re not conditionally independent given{Z1,... Zk}. Otherwise, they\nare.\nHowever, this algorithm only works if the Bayes’ Net has no Common Effect structure within the graph, be-\ncause if it exists, then two nodes are “reachable” when theY node in Common Effect is activated (observed).\nTo adjust for this, we arrive at the followingd-separation algorithm:\n1. Shade all observed nodes{Z1,..., Zk} in the graph.\n2. Enumerate all undirected paths fromX to Y.\n3. For each path:\n(a) Decompose the path into triples (segments of 3 nodes).\n(b) If all triples are active, this path is active andd-connects Xto Y.\n4. If no path d-connectsX and Y, thenX and Y are d-separated, so they are conditionally independent\ngiven {Z1,..., Zk}\nAny path in a graph fromX to Y can be decomposed into a set of 3 consecutive nodes and 2 edges - each\nof which is called a triple. A triple is active or inactive depending on whether or not the middle node is\nobserved. If all triples in a path are active, then the path is active andd-connects Xto Y, meaningX is\nnot guaranteed to be conditionally independent ofY given the observed nodes. If all paths fromX to Y are\ninactive, thenX and Y are conditionally independent given the observed nodes.\nActive triples: We can enumerate all possibilities of active and inactive triples using the three canonical\ngraphs we presented above in Figure 8 and 9.\nCS 188, Fall 2018, Note 6 11'), Document(metadata={'source': 'Data\\AI-Lecture Note 6.pdf', 'page': 11}, page_content='Figure 8: Active triples\n Figure 9: Inactive triples\nExamples\nHere are some examples of applying thed-separation algorithm:\nThis graph contains the common effect and causual\nchain canonical graphs.\na) R ??B – Guaranteed\nb) R ??B | T – Not guaranteed\nc) R ??B | T0 – Not guaranteed\nd) R ??T0 | T – Guaranteed\nCS 188, Fall 2018, Note 6 12'), Document(metadata={'source': 'Data\\AI-Lecture Note 6.pdf', 'page': 12}, page_content='This graph contains combinations of all three canon-\nical graphs (can you list them all?).\na) L ??T0 | T – Guaranteed\nb) L ??B – Guaranteed\nc) L ??B | T – Not guaranteed\nd) L ??B | T0 – Not guaranteed\ne) L ??B | T,R – Guaranteed\nThis graph contains combinations of all three canon-\nical graphs.\na) T ??D – Not guaranteed\nb) T ??D | R – Guaranteed\nc) T ??D | R,S – Not guaranteed\nConclusion\nTo summarize, Bayes’ Nets is a powerful representation of joint probability distributions. Its topological\nstructure encodes independence and conditional independence relationships, and we can use it to model\narbitrary distributions to perform inference and sampling.\nCS 188, Fall 2018, Note 6 13')]