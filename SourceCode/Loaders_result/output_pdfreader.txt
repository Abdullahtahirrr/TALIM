[{'file_name': 'AI-Lecture Note 6 Slides Version 1.pdf', 'Instructor_name': 'Dr. Seemab Latif', 'text': 'Dr. Seemab latif\nLecture 7\n12 Nov 2024\nAR T I F I C I A L  I N T E L L I G E N C E[These slides were created by Dan Klein and Pieter Abbeel for CS188 Intro to AI at UC Berkeley.]ProbabilityToday\n\uf0a7Probability\n\uf0a7Random Variables\n\uf0a7Joint and Marginal Distributions\n\uf0a7Conditional Distribution\n\uf0a7Product Rule, Chain Rule, Bayes’ Rule\n\uf0a7Inference\n\uf0a7Independence\n\uf0a7You’ll need all this stuff A LOT for the \nnext few weeks, so make sure you go \nover it now!\nInference in Ghostbusters\n\uf0a7A ghost is in the grid \nsomewhere\n\uf0a7Sensor readings tell how \nclose a square is to the \nghost\n\uf0a7On the ghost: red\n\uf0a71 or 2 away: orange\n\uf0a73 or 4 away: yellow\n\uf0a75+ away: green\nP(red | 3) P(orange | 3) P(yellow | 3) P(green | 3)\n0.05 0.15 0.5 0.3\uf0a7Sensors are noisy, but we know P(Color | Distance)\n[Demo: Ghostbuster –no probability (L12D1) ]Video of Demo Ghostbuster –No probability\nUncertainty\n\uf0a7General situation:\n\uf0a7Observed variables (evidence) : Agent knows certain \nthings about the state of the world (e.g., sensor \nreadings or symptoms)\n\uf0a7Unobserved variables : Agent needs to reason about \nother aspects (e.g. where an object is or what disease is \npresent)\n\uf0a7Model : Agent knows something about how the known \nvariables relate to the unknown variables\n\uf0a7Probabilistic reasoning gives us a framework for \nmanaging our beliefs and knowledge\nRandom Variables\n\uf0a7A random variable is some aspect of the world about \nwhich we (may) have uncertainty\n\uf0a7R = Is it raining?\n\uf0a7T = Is it hot or cold?\n\uf0a7D = How long will it take to drive to work?\n\uf0a7L = Where is the ghost?\n\uf0a7We denote random variables with capital letters\n\uf0a7Random variables have domains\n\uf0a7R in {true, false}   (often write as {+r, -r})\n\uf0a7T in {hot, cold}\n\uf0a7D in [0, \uf0a5)\n\uf0a7L in possible locations, maybe {(0,0), (0,1), …}\nProbability Distributions\n\uf0a7Associate a probability with each value\n\uf0a7Temperature:\nT P\nhot 0.5\ncold 0.5\nW P\nsun 0.6\nrain 0.1\nfog 0.3\nmeteor 0.0\n\uf0a7Weather: Shorthand notation:\nOK ifall domain entries are uniqueProbability Distributions\n\uf0a7Unobserved random variables have d'}, {'file_name': 'AI-Lecture Note 6 Slides Version 1.pdf', 'Instructor_name': 'Dr. Seemab Latif', 'text': 'istributions\n\uf0a7A distribution is a TABLE of probabilities of values\n\uf0a7A probability (lower case value) is a single number\n\uf0a7Must have:                                                 andT P\nhot 0.5\ncold 0.5\nW P\nsun 0.6\nrain 0.1\nfog 0.3\nmeteor 0.0\nJoint Distributions\n\uf0a7A joint distribution over a set of random variables:\nspecifies a real number for each assignment (or outcome ): \n\uf0a7Must obey:\n\uf0a7Size of distribution if n variables with domain sizes d?\n\uf0a7For all but the smallest distributions, impractical to write out!\nT W P\nhot sun 0.4\nhot rain 0.1\ncold sun 0.2\ncold rain 0.3\nProbabilistic Models\n\uf0a7A probabilistic model is a joint distribution \nover a set of random variables\n\uf0a7Probabilistic models:\n\uf0a7(Random) variables with domains \n\uf0a7Assignments are called outcomes\n\uf0a7Joint distributions: say whether assignments \n(outcomes) are likely\n\uf0a7Normalized: sum to 1.0\n\uf0a7Ideally: only certain variables directly interact\n\uf0a7Constraint satisfaction problems:\n\uf0a7Variables with domains\n\uf0a7Constraints: state whether assignments are \npossible\n\uf0a7Ideally: only certain variables directly interactT W P\nhot sun 0.4\nhot rain 0.1\ncold sun 0.2\ncold rain 0.3\nT W P\nhot sun T\nhot rain F\ncold sun F\ncold rain TDistribution over T,W\nConstraint over T,W\nEvents\n\uf0a7An event is a set E of outcomes\n\uf0a7From a joint distribution, we can \ncalculate the probability of any event\n\uf0a7Probability that it’s hot AND sunny?\n\uf0a7Probability that it’s hot?\n\uf0a7Probability that it’s hot OR sunny?\n\uf0a7Typically, the events we care about \nare partial assignments , like P(T=hot)T W P\nhot sun 0.4\nhot rain 0.1\ncold sun 0.2\ncold rain 0.3\nQuiz: Events\n\uf0a7P(+x, +y) ?\n\uf0a7P(+x) ?\n\uf0a7P(-y OR +x) ?X Y P\n+x +y 0.2\n+x -y 0.3\n-x +y 0.4\n-x -y 0.1\nMarginal Distributions\n\uf0a7Marginal distributions are sub -tables which eliminate variables \n\uf0a7Marginalization (summing out): Combine collapsed rows by adding\nT W P\nhot sun 0.4\nhot rain 0.1\ncold sun 0.2\ncold rain 0.3T P\nhot 0.5\ncold 0.5\nW P\nsun 0.6\nrain 0.4\nQuiz: Marginal Distributions\nX Y P\n+x +y 0.2\n+x -y 0.3\n-x +y 0.4\n-x -y 0.1X P\n+'}, {'file_name': 'AI-Lecture Note 6 Slides Version 1.pdf', 'Instructor_name': 'Dr. Seemab Latif', 'text': 'x\n-x\nY P\n+y\n-y\nConditional Probabilities\n\uf0a7A simple relation between joint and conditional probabilities\n\uf0a7In fact, this is taken as the definition of a conditional probability\nT W P\nhot sun 0.4\nhot rain 0.1\ncold sun 0.2\ncold rain 0.3\nP(b) P(a)P(a,b)\nQuiz: Conditional Probabilities\nX Y P\n+x +y 0.2\n+x -y 0.3\n-x +y 0.4\n-x -y 0.1\n\uf0a7P(+x | +y) ?\n\uf0a7P(-x | +y) ?\n\uf0a7P(-y | +x) ?Conditional Distributions\n\uf0a7Conditional distributions are probability distributions over \nsome variables given fixed values of others\nT W P\nhot sun 0.4\nhot rain 0.1\ncold sun 0.2\ncold rain 0.3W P\nsun 0.8\nrain 0.2\nW P\nsun 0.4\nrain 0.6\nConditional DistributionsJoint Distribution\nNormalization Trick\nT W P\nhot sun 0.4\nhot rain 0.1\ncold sun 0.2\ncold rain 0.3\nW P\nsun 0.4\nrain 0.6\nSELECT the joint \nprobabilities \nmatching the \nevidenceNormalization Trick\nT W P\nhot sun 0.4\nhot rain 0.1\ncold sun 0.2\ncold rain 0.3\nW P\nsun 0.4\nrain 0.6\nT W P\ncold sun 0.2\ncold rain 0.3\nNORMALIZE the \nselection\n(make it sum to one)Normalization Trick\nT W P\nhot sun 0.4\nhot rain 0.1\ncold sun 0.2\ncold rain 0.3\nW P\nsun 0.4\nrain 0.6\nT W P\ncold sun 0.2\ncold rain 0.3SELECT the joint \nprobabilities \nmatching the \nevidence\nNORMALIZE the \nselection\n(make it sum to one)\n\uf0a7Why does this work? Sum of selection is P(evidence)!  (P(T=c), here)\nQuiz: Normalization Trick\nX Y P\n+x +y 0.2\n+x -y 0.3\n-x +y 0.4\n-x -y 0.1\nSELECT the joint \nprobabilities \nmatching the \nevidenceNORMALIZE the \nselection\n(make it sum to one)\uf0a7P(X | Y= -y) ?\uf0a7(Dictionary) To bring or restore to a normal condition\n\uf0a7Procedure:\n\uf0a7Step 1: Compute Z = sum over all entries\n\uf0a7Step 2: Divide every entry by Z\n\uf0a7Example 1To Normalize\nAll entries sum to ONE\nW P\nsun 0.2\nrain 0.3 Z = 0.5W P\nsun 0.4\nrain 0.6\uf0a7Example 2\nT W P\nhot sun 20\nhot rain 5\ncold sun 10\ncold rain 15Normalize\nZ = 50NormalizeT W P\nhot sun 0.4\nhot rain 0.1\ncold sun 0.2\ncold rain 0.3Probabilistic Inference\n\uf0a7Probabilistic inference: compute a desired probability \nfrom other known probabilities (e.g. conditional from \njoint)\n\uf0a7We genera'}, {'file_name': 'AI-Lecture Note 6 Slides Version 1.pdf', 'Instructor_name': 'Dr. Seemab Latif', 'text': 'lly compute conditional probabilities \n\uf0a7P(airport on time | no reported accidents) = 0.90\n\uf0a7These represent the agent’s beliefs given the evidence\n\uf0a7Probabilities change with new evidence:\n\uf0a7P(airport on time | no accidents, 5 a.m.) = 0.95\n\uf0a7P(airport on time | no accidents, 5 a.m., raining) = 0.80\n\uf0a7Observing new evidence causes beliefs to be updatedInference by Enumeration\n\uf0a7General case:\n\uf0a7Evidence variables: \n\uf0a7Query* variable:\n\uf0a7Hidden variables:\nAll variables* Works fine with \nmultiple query \nvariables, too\uf0a7We want:\n\uf0a7Step 1: Select the \nentries consistent \nwith the evidence\uf0a7Step 2: Sum out H to get joint \nof Query and evidence\uf0a7Step 3: Normalize\n2829\n30\n31\n32\n33\n34\nInference by Enumeration\n\uf0a7P(W)?\n\uf0a7P(W | winter)?\n\uf0a7P(W | winter, hot)?S T W P\nsummer hot sun 0.30\nsummer hot rain 0.05\nsummer cold sun 0.10\nsummer cold rain 0.05\nwinter hot sun 0.10\nwinter hot rain 0.05\nwinter cold sun 0.15\nwinter cold rain 0.20\uf0a7Obvious problems:\n\uf0a7Worst -case time complexity O( dn) \n\uf0a7Space complexity O( dn) to store the joint distributionInference by EnumerationThe Product Rule\n\uf0a7Sometimes have conditional distributions but want the joint\nThe Product Rule\n\uf0a7Example:\nR P\nsun 0.8\nrain 0.2D W P\nwet sun 0.1\ndry sun 0.9\nwet rain 0.7\ndry rain 0.3\nD W P\nwet sun 0.08\ndry sun 0.72\nwet rain 0.14\ndry rain 0.06\nThe Chain Rule\n\uf0a7More generally, can always write any joint distribution as an \nincremental product of conditional distributions\n\uf0a7Why is this always true?\nBayes Rule\nBayes’ Rule\n\uf0a7Two ways to factor a joint distribution over two variables:\n\uf0a7Dividing, we get:\n\uf0a7Why is this at all helpful?\n\uf0a7Lets us build one conditional from its reverse\n\uf0a7Often one conditional is tricky but the other one is simple\n\uf0a7Foundation of many systems we’ll see later (e.g. ASR, MT)\n\uf0a7In the running for most important AI equation!\nThat’s my rule!Inference with Bayes’ Rule\n\uf0a7Example: Diagnostic probability from causal probability:\n\uf0a7Example:\n\uf0a7M: meningitis, S: stiff neck\n\uf0a7Note: posterior probability of meningitis still very small\n\uf0a7Note: y'}, {'file_name': 'AI-Lecture Note 6 Slides Version 1.pdf', 'Instructor_name': 'Dr. Seemab Latif', 'text': 'ou should still get stiff necks checked out!  Why?\nQuiz: Bayes’ Rule\n\uf0a7Given:\n\uf0a7What is P(W | dry) ? R P\nsun 0.8\nrain 0.2D W P\nwet sun 0.1\ndry sun 0.9\nwet rain 0.7\ndry rain 0.3\nGhostbusters, Revisited\n\uf0a7Let’s say we have two distributions:\n\uf0a7Prior distribution over ghost location: P(G)\n\uf0a7Let’s say this is uniform\n\uf0a7Sensor reading model: P(R | G)\n\uf0a7Given: we know what our sensors do\n\uf0a7R = reading color measured at (1,1)\n\uf0a7E.g. P(R = yellow | G=(1,1)) = 0.1\n\uf0a7We can calculate the posterior \ndistribution P(G|r) over ghost locations \ngiven a reading using Bayes’ rule:\n[Demo: Ghostbuster –with probability (L12D2) ]Video of Demo Ghostbusters with Probability\n'}, {'file_name': 'AI-Lecture Note 6 Slides Version 2.pdf', 'Instructor_name': 'Dr. Seemab Latif', 'text': "Bayes’ Nets\n[These slides were created by Dan Klein and Pieter Abbeel for CS188 Intro to AI at UC Berkeley.  All CS188 materials are avai lable at http:// ai.berkeley.edu .]Probabilistic Models\n\uf0a7Models describe how (a portion of) the world works\n\uf0a7Models are always simplifications\n\uf0a7May not account for every variable\n\uf0a7May not account for all interactions between variables\n\uf0a7“All models are wrong; but some are useful. ”\n–George E. P. Box\n\uf0a7What do we do with probabilistic models?\n\uf0a7We (or our agents) need to reason about unknown \nvariables, given evidence\n\uf0a7Example: explanation (diagnostic reasoning)\n\uf0a7Example: prediction (causal reasoning)\n\uf0a7Example: value of informationIndependence\n\uf0a7Two variables are independent if:\n\uf0a7This says that their joint distribution factors into a product two \nsimpler distributions\n\uf0a7Another form:\n\uf0a7We write: \n\uf0a7Independence is a simplifying modeling assumption\n\uf0a7Empirical joint distributions: at best “close ”to independent\n\uf0a7What could we assume for {Weather, Traffic, Cavity, Toothache}?Independence\nExample: Independence?\nT W P\nhot sun 0.4\nhot rain 0.1\ncold sun 0.2\ncold rain 0.3T W P\nhot sun 0.3\nhot rain 0.2\ncold sun 0.3\ncold rain 0.2T P\nhot 0.5\ncold 0.5\nW P\nsun 0.6\nrain 0.4\nExample: Independence\n\uf0a7N fair, independent coin flips:\nH 0.5\nT 0.5\nH 0.5\nT 0.5H 0.5\nT 0.5\nConditional Independence\n\uf0a7P(Toothache, Cavity, Catch)\n\uf0a7If I have a cavity, the probability that the probe catches in it \ndoesn't depend on whether I have a toothache:\n\uf0a7P(+catch | +toothache, +cavity) = P(+catch | +cavity)\n\uf0a7The same independence holds if I don ’t have a cavity:\n\uf0a7P(+catch | +toothache, -cavity) = P(+catch| -cavity)\n\uf0a7Catch is conditionally independent of Toothache given Cavity:\n\uf0a7P(Catch | Toothache, Cavity) = P(Catch | Cavity)\n\uf0a7Equivalent statements:\n\uf0a7P(Toothache | Catch , Cavity) = P(Toothache | Cavity)\n\uf0a7P(Toothache, Catch | Cavity) = P(Toothache | Cavity) P(Catch | Cavity)\n\uf0a7One can be derived from the other easilyConditional Independence\n\uf0a7Unconditional (absolute) independence ve"}, {'file_name': 'AI-Lecture Note 6 Slides Version 2.pdf', 'Instructor_name': 'Dr. Seemab Latif', 'text': 'ry rare (why?)\n\uf0a7Conditional independence is our most basic and robust form \nof knowledge about uncertain environments.\n\uf0a7X is conditionally independent of Y given Z\nif and only if:\nor, equivalently, if and only if\nConditional Independence\n\uf0a7What about this domain:\n\uf0a7Traffic\n\uf0a7Umbrella\n\uf0a7Raining\nConditional Independence\n\uf0a7What about this domain:\n\uf0a7Fire\n\uf0a7Smoke\n\uf0a7Alarm\nConditional Independence and the Chain Rule\n\uf0a7Chain rule: \n\uf0a7Trivial decomposition:\n\uf0a7With assumption of conditional independence:\n\uf0a7Bayes ’nets / graphical models help us express conditional independence assumptions\nInference in Ghostbusters\n\uf0a7A ghost is in the grid \nsomewhere\n\uf0a7Sensor readings tell how \nclose a square is to the \nghost\n\uf0a7On the ghost: red\n\uf0a71 or 2 away: orange\n\uf0a73 or 4 away: yellow\n\uf0a75+ away: green\nVideo of Demo Ghostbusters with Probability\n15\n16\n17\nBayes ’Nets: Big Picture\nBayes ’Nets: Big Picture\n\uf0a7Two problems with using full joint distribution tables \nas our probabilistic models:\n\uf0a7Unless there are only a few variables, the joint is WAY too \nbig to represent explicitly\n\uf0a7Hard to learn (estimate) anything empirically about more \nthan a few variables at a time\n\uf0a7Bayes ’nets: a technique for describing complex joint \ndistributions (models) using simple, local \ndistributions (conditional probabilities)\n\uf0a7More properly called graphical models\n\uf0a7We describe how variables locally interact\n\uf0a7Local interactions chain together to give global, indirect \ninteractions\n\uf0a7For about 10 min, we ’llbe vague about how these \ninteractions are specified\nGraphical Model Notation\n\uf0a7Nodes: variables (with domains)\n\uf0a7Can be assigned (observed) or unassigned \n(unobserved)\n\uf0a7Arcs: interactions\n\uf0a7Similar to CSP constraints\n\uf0a7Indicate “direct influence ”between variables\n\uf0a7Formally: encode conditional independence \n(more later)\n\uf0a7For now: imagine that arrows mean \ndirect causation (in general, they don ’t!)\nExample: Coin Flips\n\uf0a7N independent coin flips\n\uf0a7No interactions between variables: absolute independenceX1 X2 Xn\nBayes ’Net Semantics\nExam'}, {'file_name': 'AI-Lecture Note 6 Slides Version 2.pdf', 'Instructor_name': 'Dr. Seemab Latif', 'text': 'ple: Alarm Network\n\uf0a7Variables\n\uf0a7B: Burglary\n\uf0a7E: Earthquake\n\uf0a7A: Alarm goes off\n\uf0a7M: Mary calls\n\uf0a7J: John calls\n3334\n3538Example: Traffic\nR\nT+r 1/4\n-r 3/4\n+r +t 3/4\n-t 1/4\n-r +t 1/2\n-t 1/2\nExample: Traffic\n\uf0a7Causal direction\nR\nT+r 1/4\n-r 3/4\n+r +t 3/4\n-t 1/4\n-r +t 1/2\n-t 1/2+r +t 3/16\n+r -t 1/16\n-r +t 6/16\n-r -t 6/16\nExample: Reverse Traffic\n\uf0a7Reverse causality?\nT\nR+t 9/16\n-t 7/16\n+t +r 1/3\n-r 2/3\n-t +r 1/7\n-r 6/7+r +t 3/16\n+r -t 1/16\n-r +t 6/16\n-r -t 6/16\nCausality?\n\uf0a7When Bayes ’nets reflect the true causal patterns:\n\uf0a7Often simpler (nodes have fewer parents)\n\uf0a7Often easier to think about\n\uf0a7Often easier to elicit from experts\n\uf0a7BNs need not actually be causal\n\uf0a7Sometimes no causal net exists over the domain \n(especially if variables are missing)\n\uf0a7E.g. consider the variables Traffic and Drips\n\uf0a7End up with arrows that reflect correlation, not causation\n\uf0a7What do the arrows really mean?\n\uf0a7Topology may happen to encode causal structure\n\uf0a7Topology really encodes conditional independence\n43'}, {'file_name': 'AI-Lecture Note 6.pdf', 'Instructor_name': 'Dr. Seemab Latif', 'text': 'CS 188 Introduction to Artiﬁcial IntelligenceFall 2018 Note 6These lecture notes are heavily based on notes originally written by Josh Hug and Jacky Liang.Probabilistic InferenceIn artiﬁcial intelligence, we often want to model the relationships between various nondeterministic events.If the weather predicts a 40% chance of rain, should I carry my umbrella? How many scoops of ice creamshould I get if the more scoops I get, the more likely I am to drop it all? If there was an accident 15 minutesago on the freeway on my route to Oracle Arena to watch the Warriors’ game, should I leave now or in 30minutes? All of these questions (and innumerable more) can be answered withprobabilistic inference.We’re assuming that you’ve learned the foundations of probability in CS70, so these notes will not reviewbasic concepts of probability like PDFs, conditional probabilities, independence, and conditional indepen-dence.In previous sections of this class, we modeled the world as existing in a speciﬁc state that is always known.For the next several weeks, we will instead use a new model where each possible state for the world hasits own probability. For example, we might build a weather model, where the state consists of the season,temperature and weather. Our model might say thatP(winter,35\x00,cloudy)=0.023. This number representsthe probability of the speciﬁc outcome that it is winter, 35\x00, and cloudy.More precisely, our model is ajoint distribution, i.e. a table of probabilities which captures the likelihoodof each possibleoutcome, also known as anassignment. As an example, consider the table below:SeasonTemperatureWeatherProbabilitysummerhotsun0.30summerhotrain0.05summercoldsun0.10summercoldrain0.05winterhotsun0.10winterhotrain0.05wintercoldsun0.15wintercoldrain0.20This model allows us to answer questions that might be of interest to us, for example:•What is the probability that it is sunny?P(W=sun)•What is the probability distribution for the weather, given that we know it is win'}, {'file_name': 'AI-Lecture Note 6.pdf', 'Instructor_name': 'Dr. Seemab Latif', 'text': 'ter?P(W|S=winter)•What is the probability that it is winter, given that we know it is rainy and cold?P(S=winter|T=cold,W=rain)•What is the probability distribution for the weather and season give that we know that it is cold?P(S,W|T=cold)CS 188, Fall 2018, Note 61Given a joint PDF, we can trivially perform compute any desired probablity distributionP(Q1...Qk|e1...ek)using a simple and intuitive procedure known asinference by enumeration, for which we deﬁne three typesof variables we will be dealing with:1.Query variablesQi, which are unknown and appear on the left side of the probability distribution weare trying to compute.2.Evidence variablesei, which are observed variables whose values are known and appear on the rightside of the probability distribution we are trying to compute.3.Hidden variables, which are values present in the overall joint distribution but not in the distributionwe are currently trying to compute.In this procedure, we collect all the rows consistent with the observed evidence variables, sum out all thehidden variables, and ﬁnally normalize the table so that it is a probability distribution (i.e. values sum to 1).For example, if we wanted to computeP(W|S=winter), we’d select the four rows whereSis winter, thensum out overTand normalize. This yields the following probability table:WSUnnormalized SumProbabilitysunwinter0.10+0.15=0.250.25/(0.25+0.25)=0.5rainwinter0.05+0.20=0.250.25/(0.25+0.25)=0.5HenceP(W=sun|S=winter)=0.5 andP(W=rain|S=winter)=0.5, and we learn that in winterthere’s a 50% chance of sun and a 50% chance of rain (classic California weather).So long as we have the joint PDF table, inference by enumeration (IBE) can be used to compute any desiredprobablity distribution, even for multiple query variablesQ1...Qk.Bayes Nets (Representation)While inference by enumeration can compute probabilities for any query we might desire, representing anentire joint distribution in the memory of a computer is impractical for real problems - if each'}, {'file_name': 'AI-Lecture Note 6.pdf', 'Instructor_name': 'Dr. Seemab Latif', 'text': ' ofnvariableswe wish to represent can take ondpossible values (it has adomainof sized), then our joint distributiontable will havednentries, exponential in the number of variables and quite impractical to store!Bayes nets avoid this issue by taking advantage of the idea of conditional probability. Rather than storinginformation in a giant table, probabilities are instead distributed across a large number of smaller localprobability tables along with adirected acyclic graph(DAG) which captures the relationships betweenvariables. The local probability tables and the DAG together encode enough information to compute anyprobability distribution that we could have otherwise computed given the entire joint distribution.Speciﬁcally, each node in the graph represents a single random variable and each directed edge representsone of the conditional probability distributions we choose to store (i.e. an edge from nodeAto nodeBindicates that we store the probability table forP(B|A)).Each node is conditionally independent of all itsancestor nodes in the graph, given all of its parents. Thus, if we have a node representing variableX, westoreP(X|A1,A2,...,AN), whereA1,...,ANare the parents ofX.As an example of a Bayes Net, consider a model where we have ﬁve binary random variables describedbelow:CS 188, Fall 2018, Note 62•B: Burglary occurs.•A: Alarm goes off.•E: Earthquake occurs.•J: John calls.•M: Mary calls.Assume the alarm can go off if either a burglary or an earthquake occurs, and that Mary and John will callif they hear the alarm. We can represent these dependencies with the graph shown below.\nAs a reality check, it’s important to internalize that Bayes Nets are only a type of model. Models attemptto capture the way the world works, but because they are always a simpliﬁcation they are always wrong.However, with good modeling choices they can still be good enough approximations that they are useful forsolving real problems in the real world. In general, they will not account '}, {'file_name': 'AI-Lecture Note 6.pdf', 'Instructor_name': 'Dr. Seemab Latif', 'text': 'for every variable or even everyinteraction between variables.Returning to our discussion, we formally deﬁne a Bayes Net as consisting of:•A directed acyclic graph of nodes, one per variableX.•A conditional distribution for each nodeP(X|A1...An), whereAiis theithparent ofX, stored as aconditional probability tableor CPT. Each CPT hasn+2 columns: one for the values of each of thenparent variablesA1...An, one for the values ofX, and one for the conditional probability ofX.In the alarm model above, we would store probability tablesP(B),P(E),P(A|B,E),P(J|A)andP(M|A).Given all of the CPTs for a graph, we can calculate the probability of a given assignment using the chainrule:P(X1,X2,...,Xn)=’ni=1P(Xi|parents(Xi)).For the alarm model above, we might calculate the probability of one event as follows:P(\x00b,\x00e,+a,+j,\x00m)=P(\x00b)·P(\x00e)·P(+a|\x00b,\x00e)·P(+j|+a)·P(\x00m|+a).CS 188, Fall 2018, Note 63This works because of the conditional independence relationships given by the graph. Speciﬁcally, we relyon the fact thatP(xi|x1,...,xi\x001)=P(xi|parents(Xi)). Or in other words, that the probability of a speciﬁcvalue ofXidepends only on the values assigned toXi’s parents.Bayes Nets (Inference)Inference is the process of calculating the joint PDF for some set of query variables based on some setof observed variables. We can solve this problem naively by forming the joint PDF and using inference byenumeration as described above. This requires the creation of and iteration over an exponentially large table.An alternate approach is toeliminatevariables one by one. To eliminate a variableX, we:1.Join (multiply together) all factors involvingX.2.Sum outX.Afactoris deﬁned simply as anunnormalized probability. At all points during variable elimination, eachfactor will be proportional to the probability it corresponds to but the underlying distribution for each factorwon’t necessarily sum to 1 as a probability distribution should.Let’s make these ideas more concrete with an example. Suppose we have a mo'}, {'file_name': 'AI-Lecture Note 6.pdf', 'Instructor_name': 'Dr. Seemab Latif', 'text': 'del as shown below, whereT,C,S, andEcan take on binary values, as shown below. Here,Trepresents the chance that an adventurertakes a treasure,Crepresents the chance that a cage falls on the adventurer given that he takes the treasure,Srepresents the chance that snakes are released if an adventurer takes the treasure, andErepresents thechance that the adventurer escapes given information about the status of the cage and snakes.\nIn this case, we have the factorsP(T),P(C|T),P(S|T), andP(E|C,S). Suppose we want to calculateP(T|+e). The inference by enumeration approach would be to form the 16 row joint PDFP(T,C,S,E),select only the rows corresponding to +e, then summing outCandSand ﬁnally normalizing.The alternate approach is to eliminateC, thenS, one variable at a time. We’d proceed as follows:•Join (multiply) all the factors involvingC, formingP(C,+e|T,S)=P(C|T)·P(+e|C,S).•Sum outCfrom this new factor, leaving us with a new factorP(+e|T,S).•Join all factors involvingS, formingP(+e,S|T)=P(S|T)·P(+e|T,S).CS 188, Fall 2018, Note 64•Sum outS, yieldingP(+e|T).Once we haveP(+e|T), we can easily computeP(T|+e).While this process is more involved from a conceptual point of view, the maximum size of any factorgenerated is only 8 rows instead of 16 as it would be if we formed the entire joint PDF.An alternate way of looking at the problem is to observe that the calculation ofP(+e,T)can either be done,as it is in inference by enumeration, as follows:ÂsÂcP(T)P(s|T)P(c|T)P(+e|c,s)Variable elimination is equivalent to calculatingP(+e,T)as follows:P(T)ÂsP(s|T)ÂcP(c|T)P(+e|c,s)Bayes Nets (Sampling)An alternate approach for probabilistic reasoning is to implicitly calculate the probabilities for our query bysimply counting samples.For example, suppose we wanted to calculateP(T|+e). If we had a magic machine that could generatesamples from our distribution, we could collect all samples for which the adventurer escapes the maze, andthen compute the fraction of those escapes for which th'}, {'file_name': 'AI-Lecture Note 6.pdf', 'Instructor_name': 'Dr. Seemab Latif', 'text': 'e adventurer also took the treasure. Put differently,if we could run simulations of say, a few million adventurers, we’d easily be able to compute any inferencewe’d want just by looking at the samples.Given a Bayes Net model, we can easily write a simulator. For example, consider the CPTs given below forthe simpliﬁed model with only two variables T and C.\nCS 188, Fall 2018, Note 65A simple simulator in Python would be as follows:import randomdef get_t():if random.random() < 0.99:return Truereturn Falsedef get_c(t):if t and random.random() < 0.95:return Truereturn Falsedef get_sample():t = get_t()c = get_c(t)return [t, c]We call this simple approachprior sampling. The downside of this approach is that it may require thegeneration of a very large number of samples in order to perform analysis of unlikely scenarios. If wewanted to computeP(C|\x00t), we’d have to throw away 99% of our samples.One way to mitigate this this problem, we can modify our procedure to early reject any sample inconsistentwith our evidence. For example, for the queryP(C|\x00t), we’d avoid generating a value for C unless t is true.This still means we have to throw away most of our samples, but at least the bad samples we generate takeless time to create. We call this approachrejection sampling.These two approaches work for the same reason, which is that any valid sample occurs with the sameprobability as speciﬁed in the joint PDF. In other words, the probability of every sample is based on theproduct of every CPT, or as I personally call it, the "every CPT participates principle".A more exotic approach islikelihood weighting, which ensures that we never generate a bad sample. Inthis approach, we manually set all variables equal to the evidence in our query. For example, if we wantedto computeP(C|\x00t), we’d simply declare that t is false. The problem here is that this may yield samplesthat are inconsistent with the correct distribution. As an example, consider the more complex four variablemodel for T, C'}, {'file_name': 'AI-Lecture Note 6.pdf', 'Instructor_name': 'Dr. Seemab Latif', 'text': ', S, and E given earlier in these notes. If we wanted to computeP(T,S,+c,+e), and simplypicked values for T and S without taking into account the fact that c = false, and e = true, then there’s noguarantee that our samples actually obey the joint PDF given by the Bayes Net. For example, if the cageonly ever falls if the treasure is taken, then we’d want to ensure that T is always true instead of using theP(T)distribution given in the Bayes Net.Put differently, if we simply force some variables equal to the evidence, then our samples occur with proba-bility given only equal to the products of the CPTs of the non-evidence variables. This means the joint PDFhas no guarantee of being correct (though may be for some cases like our two variable Bayes Net). Instead,if we have sampled variablesZ1throughZpand ﬁxed evidence variablesE1throughEma sample is givenby the probabilityP(Z1...Zp,E1...Em)=’piP(Zi)|Parents(Zi). What is missing is that the probability of asample does not include all the probabilities ofP(Ei|Parents(Ei)), i.e. not every CPT participates.Likelihood weighting solves this issue by using a weight for each sample, which is the probability of theevidence variables given the sampled variables. That is, instead of counting all samples equally, we canCS 188, Fall 2018, Note 66deﬁne a weightwjfor samplejthat reﬂects how likely the observed values for the evidence variables are,given the sampled values. In this way, we ensure that every CPT participates. To do this, we iterate througheach variable in the Bayes net, as we do for normal sampling), sampling a value if the variable is not anevidence variable, or changing the weight for the sample if the variable is evidence.For example, suppose we want to calculateP(T|+c,+e). For thejth sample, we’d perform the followingalgorithm:•Setwjto 1.0, andc= true ande= true.•ForT: This is not an evidence variable, so we sampletjfromP(T).•ForC: This is an evidence variable, so we multiply the weight of the sample byP(+c|tj), i.e'}, {'file_name': 'AI-Lecture Note 6.pdf', 'Instructor_name': 'Dr. Seemab Latif', 'text': '.wj=wj·P(+c|tj).•ForS: samplesjfromP(S|tj).•ForE: multiply the weight of the sample byP(+e|+c,sj), i.e.wj=wj·P(+e|+c,sj).Then when we perform the usual counting process, we weight samplejbywjinstead of 1, where 0<=wj<=1. This approach works because in the ﬁnal calculations for the probabilities, the weights effectivelyserve to replace the missing CPTs. In effect, we ensure that the weighted probability of each sample is givenbyP(z1...zp,e1...em)=[’piP(zi|Parents(zi))]·[’miP(ei)|Parents(ei))].For all three of our sampling methods (prior sampling, rejection sampling, and likelihod weighting), wecan get increasing amounts of accuracy by generating additional samples. However, of the three, likelihoodweighting is the most computationally efﬁcient, for reasons beyond the scope of this course.Gibbs Sampling is a fourth approach for sampling. In this approach, we ﬁrst set all variables to some totallyrandom value (not taking into account any CPTs). We then repeatedly pick one variable at a time, clear itsvalue, and resample it given the values currently assigned to all other variables.For theT,C,S,Eexample above, we might assign t = true, c = true, s = false, and e = true. We then pickone of our four variables to resample, sayS, and clear it. We then pick a new variable from the distributionP(S|+t,+c,+e). This requires us knowing this conditional distribution. It turns out that we can easilycompute the distribution of any single variable given all other variables. More speciﬁcally,P(S|T,C,E)canbe calculated only using the CPTs that connect S with its neighbors. Thus, in a typical Bayes Net, wheremost variables have only a small number of neighbors, we can precompute the conditional distributions foreach variable given all of its neighbors in linear time.We will not prove this, but if we repeat this process enough times, our later samples will eventually convergeto the correct distribution even though we may start from a low-probability assignment of values. If you’recuriou'}, {'file_name': 'AI-Lecture Note 6.pdf', 'Instructor_name': 'Dr. Seemab Latif', 'text': 's, there are some caveats beyond the scope of the course that you can read about under the FailureModes section of the Wikipedia article for Gibbs Sampling.Bayes Nets (D-Separation)One useful question to ask about a set of random variables is whether or not one variable is independent fromanother, or if one random variable is conditionally independent of another given a third random variable.Bayes’ Nets representation of joint probability distributions gives us a way to quickly answer such questionsby inspecting the topological structure of the graph.CS 188, Fall 2018, Note 67We already mentioned thata node is conditionally independent of all its ancestor nodes in the graphgiven all of its parents.We will present all three canonical cases of connected three-node two-edge Bayes’ Nets, or triples, and theconditional independence relationships they express.Causal Chains\nFigure 1: Causal Chain with no observations.\nFigure 2: Causal Chain withYobserved.Figure 1 is a conﬁguration of three nodes known as acausal chain. It expresses the following representationof the joint distribution overX,Y, andZ:P(x,y,z)=P(z|y)P(y|x)P(x)It’s important to note thatXandZare not guaranteed to be independent, as shown by the following coun-terexample:P(y|x)=(1 ifx=y0 elseP(z|y)=(1 ifz=y0 elseIn this case,P(z|x)=1 ifx=zand 0 otherwise, soXandZare not independent.However, we can make the statement thatX??Z|Y, as in Figure 2. Recall that this conditional indepdencemeans:P(X|Z,Y)=P(X|Y)We can prove this statement as follows:P(X|Z,y)=P(X,Z,y)P(Z,y)=P(Z|y)P(y|X)P(X)ÂxP(X,y,Z)=P(Z|y)P(y|X)P(X)P(Z|y)ÂxP(y|x)P(x)=P(y|X)P(X)ÂxP(y|x)P(x)=P(y|X)P(X)P(y)=P(X|y)An analogous proof can be used to show the same thing for the case whereXhas multiple parents. Tosummarize, in the causal chain chain conﬁguration,X??Z|Y.Common CauseAnother possible conﬁguration for a triple is thecommon cause. It expresses the following representation:P(x,y,z)=P(x|y)P(z|y)P(y)Just like with causal chain, we can show thatXis not '}, {'file_name': 'AI-Lecture Note 6.pdf', 'Instructor_name': 'Dr. Seemab Latif', 'text': 'guaranteed to be independent ofZwith the followingcounterexample distribution:CS 188, Fall 2018, Note 68Figure 3: Common Cause with no observations.\nFigure 4: Common Cause withYobserved.P(x|y)=(1 ifx=y0 elseP(z|y)=(1 ifz=y0 elseThenP(x|z)=1 ifx=zand 0 otherwise, soXandZare not independent.But it is true thatX??Z|Y. That is,XandZare independent ifYis observed as in Figure 4. We can showthis as follows:P(X|Z,y)=P(X,Z,y)P(Z,y)=P(X|y)P(Z|y)P(y)P(Z|y)P(y)=P(X|y)Common E↵ectThe ﬁnal possible conﬁguration for a triple is thecommon effect, as shown in the ﬁgures below.\nFigure 5: Common Effect with no observations.\nFigure 6: Common Effect withYobserved.It expresses the representation:P(x,y,z)=P(y|x,z)P(x)P(z)In the conﬁguration shown in Figure 5,XandZare independent:X??Z. However, they are not necessarilyindependent when conditioned onY(Figure 6). As an example, suppose all three are binary variables.XCS 188, Fall 2018, Note 69andZare true and false with equal probability:P(X=true)=P(X=f alse)=0.5P(Z=true)=P(Z=f alse)=0.5andYis determined by whetherXandZhave the same value:P(Y|X,Z)=8><>:1 ifX=ZandY=true1 ifX6=ZandY=f alse0 elseThenXandZare independent ifYis unobserved. But ifYis observed, then knowingXwill tell us the valueofZ, and vice-versa. SoXandZarenotconditionally independent givenY.Common Effect can be viewed as “opposite” to Causal Chains and Common Cause –XandZare guaranteedto be independent ifYis not conditioned on. But when conditioned onY,XandZmay be dependentdepending on the speciﬁc probability values forP(Y|X,Z)).This same logic applies when conditioning on descendents ofYin the graph. If one ofY’s descendent nodesis observed, as in Figure 7,XandZare not guaranteed to be independent.\nFigure 7: Common Effect with child observations.General Case, and D-separationWe can use the previous three cases as building blocks to help us answer conditional independence questionson an arbitrary Bayes’ Net with more than three nodes and two edges. We formulate the problem as '}, {'file_name': 'AI-Lecture Note 6.pdf', 'Instructor_name': 'Dr. Seemab Latif', 'text': 'follows:Given a Bayes NetG, two nodesXandY, and a (possibly empty) set of nodes{Z1,...Zk}that representobserved variables, must the following statement be true:X??Y|{Z1,...Zk}?D-separation(directed separation) is a property of the structure of the Bayes Net graph that implies thisconditional independence relationship, and generalizes the cases we’ve seen above. If a set of variablesZ1,···Zkd-separatesXandY, thenX??Y|{Z1,···Zk}in all possible distributions that can be encoded bythe Bayes net.CS 188, Fall 2018, Note 610We start with an algorithm that is based on a notion of reachability from nodeXto nodeY.(Note: thisalgorithm is not quite correct! We’ll see how to ﬁx it in a moment.)1.Shade all observed nodes{Z1,...Zk}in the graph.2.If there exists an undirected path fromXandYthat is not blocked by a shaded node,XandYare“connected”.3.IfXandYare connected, they’re not conditionally independent given{Z1,...Zk}. Otherwise, theyare.However, this algorithm only works if the Bayes’ Net has no Common Effect structure within the graph, be-cause if it exists, then two nodes are “reachable” when theYnode in Common Effect is activated (observed).To adjust for this, we arrive at the followingd-separation algorithm:1.Shade all observed nodes{Z1,...,Zk}in the graph.2.Enumerate all undirected paths fromXtoY.3.For each path:(a)Decompose the path into triples (segments of 3 nodes).(b)If all triples are active, this path is active andd-connects XtoY.4.If no path d-connectsXandY, thenXandYare d-separated, so they are conditionally independentgiven{Z1,...,Zk}Any path in a graph fromXtoYcan be decomposed into a set of 3 consecutive nodes and 2 edges - eachof which is called a triple. A triple is active or inactive depending on whether or not the middle node isobserved. If all triples in a path are active, then the path is active andd-connects XtoY, meaningXisnot guaranteed to be conditionally independent ofYgiven the observed nodes. If all paths fromXtoYareinactive, thenXandYare condition'}, {'file_name': 'AI-Lecture Note 6.pdf', 'Instructor_name': 'Dr. Seemab Latif', 'text': 'ally independent given the observed nodes.Active triples: We can enumerate all possibilities of active and inactive triples using the three canonicalgraphs we presented above in Figure 8 and 9.\nCS 188, Fall 2018, Note 611Figure 8: Active triples\nFigure 9: Inactive triplesExamplesHere are some examples of applying thed-separation algorithm:\nThis graph contains the common effect and causualchain canonical graphs.a)R??B– Guaranteedb)R??B|T– Not guaranteedc)R??B|T0– Not guaranteedd)R??T0|T– Guaranteed\nCS 188, Fall 2018, Note 612This graph contains combinations of all three canon-ical graphs (can you list them all?).a)L??T0|T– Guaranteedb)L??B– Guaranteedc)L??B|T– Not guaranteedd)L??B|T0– Not guaranteede)L??B|T,R– Guaranteed\nThis graph contains combinations of all three canon-ical graphs.a)T??D– Not guaranteedb)T??D|R– Guaranteedc)T??D|R,S– Not guaranteedConclusionTo summarize, Bayes’ Nets is a powerful representation of joint probability distributions. Its topologicalstructure encodes independence and conditional independence relationships, and we can use it to modelarbitrary distributions to perform inference and sampling.CS 188, Fall 2018, Note 613'}]